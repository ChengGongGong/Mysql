# 1. 数据分片
    将大数据表分解为较小的表（称为分片）的过程，这些分片分布在多个数据库集群节点上，
    每个分片上包含原有总数据集的一个子集，可以将总负载分散在各个分区之上。
    
    1. 方式：
      1. 水平分片：在不同的数据库节点中存储同一表的不同行。
      2. 垂直分片：在不同的数据库节点中存储表不同的表列。
    2. 分片算法(指代水平分片所需要的算法)：
      
      1. 哈希分片：首先需要获取分片键，然后根据特定的哈希算法计算它的哈希值，最后使用哈希值确定数据应被放置在哪个分片中。
        适合随机读写的场景，很好地分散系统负载，但是不利于范围扫描查询操作。
      2. 范围分片：根据数据值或键空间的范围对数据进行划分，相邻的分片键更有可能落入相同的分片上。
        需要选择合适的分片键，这些分片键需要尽量不包含重复数值，也就是其候选数值尽可能地离散，同时数据不要单调递增或递减。
      3. 地理位置算法
        一般用于 NewSQL 数据库，提供全球范围内分布数据的能力，数据被映射到特定的分片，而这些分片又被映射到特定区域以及这些区域中的节点。
        然后在给定区域内，使用哈希或范围分片对数据进行分片。
      4. 融合算法
        建立一个多级分片策略，该策略在最上层使用哈希算法，而在每个基于哈希的分片单元中，数据将按顺序存储。
    3. 手动分片
      设置静态规则来将数据根据分片算法分散到数据库节点，一般是由于用户使用的数据库不支持自动的分片；
      可以在应用层面上做数据分片来解决，也可以使用简单的数据库中间件或 Proxy 来设置静态的分片规则来解决。
      缺点：
        数据分布不均匀，数据分布不均可能导致数据库负载极其不平衡
 # 2. 数据复制
      在几个不同的数据库节点上保留相同数据的副本，从而提供一种数据冗余。这份冗余的数据可以提高数据查询性能，而更重要的是保证数据库的可用性。
      
## 2.1. 单主复制：主从复制
      客户要写入数据库时，必须将请求发送给主节点，而后主节点将这些数据转换为复制日志或修改数据流发送给其所有从节点。
      
      1. 复制同步模式：同步复制、半同步复制、异步复制(不管从库的复制情况如何，主库可以写入该数据。而此时，如果主库失效，那么还未同步到从库的数据就会丢失)；
      2. 复制延迟：同步复制时，每次写入都需要同步所有从节点，会造成一部分从节点已经有数据，但是主节点还没写入数据；而异步复制的问题是从节点的数据可能不是最新的；
      3. 复制与高可用性：从节点故障、主节点故障
      4. 复制方式：基于语句的复制、日志(WAL)同步、行复制、ETL工具
## 2.2. 多主复制：主主复制
      数据库集群内存在多个对等的主节点，它们可以同时接受写入，每个主节点同时充当主节点的从节点。
      优点：
          1. 获得更好的写入性能：使数据可以就近写入；
          2. 数据中心级别的高可用：每个数据中心可以独立于其他数据中心继续运行；
          3. 更好的数据访问性能：用户可以访问到距离他最近的数据中心。
       缺点：
          1. 存在一种可能性，即两个不同的主节点同时修改相同的数据。
          2. 处理客户端离线操作的一致性问题
## 2.3. MySQL复制技术的发展
    1. 传统复制，主从高可用，适用场景：MySQL 的版本≤5.5;只用于异步复制且一主多从环境；基于传统复制的高可用
    2. 半同步复制
      1. binlog 使用半同步，而第一代是异步同步，它保障了数据安全，一般至少要同步两个节点；
      2. 保留异步复制，保障了复制性能，通过监控复制的延迟；
      3. 引入配置中心，对外提供健康的 MySQL 服务；
      4. 需要支持跨 IDC 复制。需要引入监控 Monitor，配合 consul 注册中心；
      
        问题：
          1. 存在幻读的情况。当事务同步到从库但没有 ACK 时，主库发生宕机；此时主库没有该事务，而从库有。
          2. MySQL 5.6 本身半同步 ACK 确认在 dump_thread 中，dump_thread 存在 IO 瓶颈问题。
     3. 增强半同步复制
        1. 主从的复制都是用独立的线程来运行；
        2. 主库采用 binlog group commit，也就是组提交来提供数据库的写入性能；
        3. 从库采用并行复制，它是基于事务的，通过数据参数调整线程数量来提高性能
        问题：
          幽灵事务：数据写入 binlog 后，主库掉电。
          由于故障恢复流程需要从 binlog 中恢复，那么这份数据就在主库。
          但是如果它没有被同步到从库，就会造成从库不能切换为主库，只能去尝试恢复原崩溃的主库
     4. MySQL 组复制
        1. 支持多主复制，同时保留单主复制的功能。
        2. 组复制的多主技术需要 Paxos 算法深度参与，并去决定每一次数据的写入，解决写入冲突。
        优点：
          1. 高可用分片：：数据库节点动态添加和移除。分片实现写扩展，每个分片是一个复制组。
          2. 自动化故障检测与容错：如果一个节点无法响应，组内大多数成员认为该节点已不正常，则自动隔离；
          3. 方案完整
     5. 注，无主复制技术
        1. 所有的副本都支持直接接受客户端的请求，客户端直接对多副本统一进行写操作，由一个类似代理节点，帮助客户端进行统一的写操作
        2. 节点失效时写入数据：
            1. 读修复，在客户端进行数据读取的时候，会从多个副本获取数据，可以通过时间戳标志的方式来判断最新数据，对存在旧数据的节点发送数据更新的请求；
            2. 反熵处理，用定期执行的后台进程扫描各个节点的差异数据，但是需要按照版本号比较大量数据并进行更新操作，数据更新有较大的延时；
        3. 读写确认
            如果有n个节点，w个法定票数（判定是否写入成功），读取至少需要r个节点，则只要 w + r > n 则读取到的数据必然包含最新值；
            w<n时，写操作允许节点不可用；
            r<n时，读操作允许节点不可用；
            对于w+r>n的情况，允许最多w+r-n个节点不可用；
            出现的问题：
                1. 并发写入时发生冲突，如果按照最后写入获胜的话可能会丢失数据；
                2. 读写操作并发进行时不保证读到最新数据；
                3. 写入操作失败时可能需要多个节点进行数据回滚操作；
         4. 客户端有时无法与所有数据节点连接，这是处理读写操作时有两种策略：
            1. 由于无法连接所有节点，当无法达到w或者r节点要求时报错；
            2. 接受写操作，无法达到w和r要求时写到其他数据节点上
 # 3. 存储引擎
 ## 3.1 存储引擎的定位
    执行层本地运行单元其实就是存储引擎。功能如下：
    1. 事务管理器：用来调度事务并保证数据库的内部一致性；
    2. 锁管理：保证操作共享对象时候的一致性，包括事务、修改数据库参数都会使用到它；
    3. 存储结构：包含各种物理存储层，描述了数据与索引是如何组织在磁盘上的；
    4. 内存结构：主要包含缓存与缓冲管理，数据一般是批量输入磁盘的，写入之前会使用内存去缓存数据；
    5. 提交日志：当数据库崩溃后，可以使用提交日志恢复系统的一致性状态。
## 3.2 内存与磁盘Redis、NuoDB 和 MySQL Cluster 等
    1. 内存型存储是把数据主要存储在内存里，加快数据读写性能，但是内存的成本较高，且容量有限。常见的包括：Redis、NuoDB 和 MySQL Cluster 等；
    2. 磁盘型存储：磁盘存储主要数据，而内存主要作为缓冲来使写入批量化，存储性价比高，但是需要处理如数据引用、文件序列化、碎片整理等复杂的操作
## 3.3 行式存储与列式存储
    1. 行式存储：每行的所有列存储在一起，从而形成数据文件；
    2. 列式存储：不同行的同一列数据会被就近存储在一个数据文件中。还需要存储该数据属于哪行。非常适合处理分析聚合类型的任务
 ## 3.4 索引
    1. 数据文件：最传统的形式为堆组织表（Heap-Organized Table），数据的放置没有一个特别的顺序，一般是按照写入的先后顺序排布；
    2. 哈希组织表：将数据通过哈希函数分散到一组数据桶内，桶内的数据一般是按照一定规则进行排序，以提高查询效率；
    3. 索引组织表（Index-Organized Table）：采用索引文件的形式来存储数据，
        索引文件的分类模式一般为主键索引与二级索引两类。前者是建立在主键上的，它可能是一个字段或多个字段组成。而其他类型的索引都被称为二级索引。
    4. 读取路径：
        1. 寻找分片和目标节点；
        2. 检查数据是否在缓存与缓冲中；
        3. 检查数据是否在磁盘文件中；
        4. 合并结果。
    5. 索引数据表：分布式数据库中最常见的是 Google 的 BigTable 论文所提到的 SSTable（排序字符串表）。
       1. SSTable 文件：一个排序的、不可变的、持久化的键值对结构，其中键值对可以是任意字节的字符串，支持使用指定键来查找值，或通过给定键范围遍历所有的键值对。
           每个 SSTable 文件包含一系列的块。
           SSTable 文件中的块索引（这些块索引通常保存在文件尾部区域）用于定位块，这些块索引在 SSTable 文件被打开时加载到内存。
           读取方式：
            1. 在查找时首先从内存中的索引二分查找找到块，然后一次磁盘寻道即可读取到相应的块。
            2. 将 SSTable 文件完全加载到内存，从而在查找和扫描中就不需要读取磁盘。
        2. B 树索引： MongoDB 的 WiredTiger 存储引擎使 B 树来存储数据，采用缓存最近的对索引的操作，而后将操作固化到磁盘中的方式优化B树的效率
            在内存页中，B 树节点带有一个修改缓冲，这个缓冲保存的一个指向磁盘原始数据的引用。在读取流程中，原始磁盘数据结合内存缓冲数据后，再返回给用户
    6. 内存缓冲：有很多种不同的数据结构可以在内存中存储有序的数据。
        1. 跳表（SkipList）：在插入和更新时避免对节点做旋转或替换，而是使用了随机平衡的概念来使整个表平衡
 
 
 
 
 
 
